{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/05/15 16:42:01 WARN Utils: Your hostname, Yzeys-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 172.30.192.255 instead (on interface en0)\n",
      "24/05/15 16:42:01 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/05/15 16:42:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/15 16:42:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bounds_coordinates(bin_bounds):\n",
    "\n",
    "    lower_cdnts = [[low] for low in  bin_bounds[0][:-1]]\n",
    "    upper_cdnts = [[high] for high in bin_bounds[0][1:]]\n",
    "    \n",
    "    # super stupid implementation, optimization needed\n",
    "    for bound in bin_bounds[1:]:\n",
    "        lower_tmp = []\n",
    "        upper_tmp = []\n",
    "        \n",
    "        for bc in bound[:-1]:\n",
    "            lower_tmp.extend([lc + [bc] for lc in lower_cdnts])\n",
    "        lower_cdnts = lower_tmp\n",
    "        \n",
    "        for bc in bound[1:]:\n",
    "            upper_tmp.extend([uc + [bc] for uc in upper_cdnts])\n",
    "        upper_cdnts = upper_tmp\n",
    "        \n",
    "    return np.array(lower_cdnts), np.array(upper_cdnts)\n",
    "\n",
    "def spatial_partition(dataset, par_each_dim, eps, withbuffer=True):\n",
    "    \"\"\"\n",
    "    Partitions the given dataset into spatial bins based on the specified parameters.\n",
    "\n",
    "    Args:\n",
    "        dataset (numpy.ndarray): The input dataset to be partitioned.\n",
    "        par_each_dim (tuple): A tuple specifying the number of partitions in each dimension.\n",
    "        eps (float): A value representing the maximum distance between two samples.\n",
    "\n",
    "    Returns:\n",
    "        pyspark.rdd.RDD: An RDD containing the indexed data, where each element is a tuple\n",
    "        of the partition ID and a list of point IDs belonging to that partition.\n",
    "    \"\"\"\n",
    "    num_par = np.prod(par_each_dim)\n",
    "    \n",
    "    # partition each dimension\n",
    "    bin_bounds = []\n",
    "    for i in range(dataset.shape[1]):\n",
    "        dim_bins = np.histogram_bin_edges(dataset[:, i], bins=par_each_dim[i])\n",
    "        bin_bounds.append(dim_bins)\n",
    "        \n",
    "    lower_bounds, upper_bounds = _bounds_coordinates(bin_bounds)\n",
    "    if withbuffer:\n",
    "        lower_bounds -= eps\n",
    "        upper_bounds += eps\n",
    "        if np.min(upper_bounds-lower_bounds) < 2*eps:\n",
    "            raise Warning('Partitions Overlap too much')\n",
    "\n",
    "    # scatter points into bins with eps\n",
    "    indexed_data = []\n",
    "    # double loop to ensure border points could be given multiple partition ID\n",
    "    for id_pts in range(len(dataset)):     # index of point in dataset\n",
    "        for id_ptt in range(num_par):\n",
    "            if not (dataset[id_pts] > lower_bounds[id_ptt]).all():\n",
    "                continue\n",
    "            if not (dataset[id_pts] < upper_bounds[id_ptt]).all():\n",
    "                continue\n",
    "            indexed_data.append([id_ptt, id_pts])\n",
    "            \n",
    "    res = sc.parallelize(indexed_data).groupByKey().map(lambda x: [x[0], list(x[1])])\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate random dataset with 3 dimensions\n",
    "n_samples = 100  # Number of samples\n",
    "n_features = 3  # Number of dimensions\n",
    "centers = 3  # Number of clusters\n",
    "random_state = 42  # Random state for reproducibility\n",
    "\n",
    "X, y = make_blobs(n_samples=n_samples, n_features=n_features, centers=centers, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "min_pts = 18\n",
    "eps = 2\n",
    "dataset = X\n",
    "b_dataset = sc.broadcast(dataset)\n",
    "b_eps = sc.broadcast(eps)\n",
    "b_min_pts = sc.broadcast(min_pts)\n",
    "partition_each_dim = (2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-10.83328933,   4.5123324 ],\n",
       "       [ -8.24949825,  10.41824487],\n",
       "       [ -8.02990217,   8.01217509]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_par = partition_each_dim\n",
    "num_par = np.prod(partition_each_dim)\n",
    "\n",
    "# cut bins\n",
    "bounds_dim = np.concatenate(([np.min(dataset, axis=0)], [np.max(dataset, axis=0)]), axis=0).T   # (d, 2)\n",
    "bounds_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-10.94162222,  -3.19208325,   4.55745572]),\n",
       " array([-8.33199323,  1.09521704, 10.52242732]),\n",
       " array([-8.11020119, -0.00895218,  8.09229684])]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_bounds = []\n",
    "for i in range(len(partition_each_dim)):\n",
    "    Lower_bound = bounds_dim[i][0] - abs(bounds_dim[i][0]) * 0.01\n",
    "    Upper_bound = bounds_dim[i][-1] + abs(bounds_dim[i][-1]) * 0.01\n",
    "    dim_bins = np.linspace(Lower_bound, Upper_bound, partition_each_dim[i]+1, endpoint=True)\n",
    "    bin_bounds.append(dim_bins)\n",
    "bin_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.24949825,  1.08437331, 10.41824487])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i= 1\n",
    "np.linspace(*bounds_dim[i], partition_each_dim[i]+1, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-10.83328933,  -3.16047846,   4.5123324 ]),\n",
       " array([-8.24949825,  1.08437331, 10.41824487]),\n",
       " array([-8.02990217, -0.00886354,  8.01217509])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_bounds = []\n",
    "for i in range(X.shape[1]):\n",
    "    dim_bins = np.histogram_bin_edges(X[:, i], bins=partition_each_dim[i])\n",
    "    bin_bounds.append(dim_bins)\n",
    "\n",
    "bin_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-10.83328933  -8.02990217]\n",
      " [ -3.16047846   1.08437331]\n",
      " [  4.5123324   10.41824487]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bin_bounds = [np.array([-10.83328933,  -3.16047846,   4.5123324 ]),\n",
    "              np.array([-8.24949825,  1.08437331, 10.41824487]),\n",
    "              np.array([-8.02990217, -0.00886354,  8.01217509])]\n",
    "\n",
    "bounds = np.vstack(bin_bounds)\n",
    "subspace_bounds = np.column_stack((np.min(bounds, axis=0), np.max(bounds, axis=0)))\n",
    "\n",
    "print(subspace_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-10.83328932819366, -8.249498247867567, -8.029902170770304)\n",
      "(-10.83328932819366, -8.249498247867567, -0.008863540457765495)\n",
      "(-10.83328932819366, -8.249498247867567, 8.012175089854775)\n",
      "(-10.83328932819366, 1.0843733094950245, -8.029902170770304)\n",
      "(-10.83328932819366, 1.0843733094950245, -0.008863540457765495)\n",
      "(-10.83328932819366, 1.0843733094950245, 8.012175089854775)\n",
      "(-10.83328932819366, 10.418244866857616, -8.029902170770304)\n",
      "(-10.83328932819366, 10.418244866857616, -0.008863540457765495)\n",
      "(-10.83328932819366, 10.418244866857616, 8.012175089854775)\n",
      "(-3.1604784639917973, -8.249498247867567, -8.029902170770304)\n",
      "(-3.1604784639917973, -8.249498247867567, -0.008863540457765495)\n",
      "(-3.1604784639917973, -8.249498247867567, 8.012175089854775)\n",
      "(-3.1604784639917973, 1.0843733094950245, -8.029902170770304)\n",
      "(-3.1604784639917973, 1.0843733094950245, -0.008863540457765495)\n",
      "(-3.1604784639917973, 1.0843733094950245, 8.012175089854775)\n",
      "(-3.1604784639917973, 10.418244866857616, -8.029902170770304)\n",
      "(-3.1604784639917973, 10.418244866857616, -0.008863540457765495)\n",
      "(-3.1604784639917973, 10.418244866857616, 8.012175089854775)\n",
      "(4.512332400210065, -8.249498247867567, -8.029902170770304)\n",
      "(4.512332400210065, -8.249498247867567, -0.008863540457765495)\n",
      "(4.512332400210065, -8.249498247867567, 8.012175089854775)\n",
      "(4.512332400210065, 1.0843733094950245, -8.029902170770304)\n",
      "(4.512332400210065, 1.0843733094950245, -0.008863540457765495)\n",
      "(4.512332400210065, 1.0843733094950245, 8.012175089854775)\n",
      "(4.512332400210065, 10.418244866857616, -8.029902170770304)\n",
      "(4.512332400210065, 10.418244866857616, -0.008863540457765495)\n",
      "(4.512332400210065, 10.418244866857616, 8.012175089854775)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Generate combinations of each dimension in bin_bounds\n",
    "combinations = list(itertools.product(*bin_bounds))\n",
    "\n",
    "# Print the combinations\n",
    "for combination in combinations:\n",
    "    print(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bounds, upper_bounds = _bounds_coordinates(bin_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_cdnts = [[low] for low in  bin_bounds[0][:-1]]\n",
    "upper_cdnts = [[high] for high in bin_bounds[0][1:]]\n",
    "\n",
    "# super stupid implementation, optimization needed\n",
    "for bound in bin_bounds[1:]:\n",
    "    lower_tmp = []\n",
    "    upper_tmp = []\n",
    "    \n",
    "    for bc in bound[:-1]:\n",
    "        lower_tmp.extend([lc + [bc] for lc in lower_cdnts])\n",
    "    lower_cdnts = lower_tmp\n",
    "    \n",
    "    for bc in bound[1:]:\n",
    "        upper_tmp.extend([uc + [bc] for uc in upper_cdnts])\n",
    "    upper_cdnts = upper_tmp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bounds, upper_bounds = np.array(lower_cdnts), np.array(upper_cdnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.08332893e+01, -8.24949825e+00, -8.02990217e+00],\n",
       "       [-3.16047846e+00, -8.24949825e+00, -8.02990217e+00],\n",
       "       [-1.08332893e+01,  1.08437331e+00, -8.02990217e+00],\n",
       "       [-3.16047846e+00,  1.08437331e+00, -8.02990217e+00],\n",
       "       [-1.08332893e+01, -8.24949825e+00, -8.86354046e-03],\n",
       "       [-3.16047846e+00, -8.24949825e+00, -8.86354046e-03],\n",
       "       [-1.08332893e+01,  1.08437331e+00, -8.86354046e-03],\n",
       "       [-3.16047846e+00,  1.08437331e+00, -8.86354046e-03]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.16047846e+00,  1.08437331e+00, -8.86354046e-03],\n",
       "       [ 4.51233240e+00,  1.08437331e+00, -8.86354046e-03],\n",
       "       [-3.16047846e+00,  1.04182449e+01, -8.86354046e-03],\n",
       "       [ 4.51233240e+00,  1.04182449e+01, -8.86354046e-03],\n",
       "       [-3.16047846e+00,  1.08437331e+00,  8.01217509e+00],\n",
       "       [ 4.51233240e+00,  1.08437331e+00,  8.01217509e+00],\n",
       "       [-3.16047846e+00,  1.04182449e+01,  8.01217509e+00],\n",
       "       [ 4.51233240e+00,  1.04182449e+01,  8.01217509e+00]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.digitize(5, bin_bounds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.83328933,  -3.16047846,   4.5123324 ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_bounds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.936066417092473"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_data = []\n",
    "\n",
    "for id_pts in range(len(dataset)):\n",
    "    pos_list = []\n",
    "    for i in range(dataset.shape[1]):\n",
    "        pos = np.digitize(dataset[id_pts][i], bin_bounds[i]) - 1\n",
    "        pos_list.append(pos)\n",
    "    indexed_data.append([tuple(pos_list), id_pts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_partition_id(partition_each_dim):\n",
    "    \"\"\"\n",
    "    Create all possible partition IDs based on the specified number of partitions in each dimension.\n",
    "\n",
    "    Args:\n",
    "        partition_each_dim (tuple): A tuple specifying the number of partitions in each dimension.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of all possible partition IDs.\n",
    "    \"\"\"\n",
    "    return list(itertools.product(*[range(i) for i in partition_each_dim]))\n",
    "\n",
    "partition_each_dim = (2, 2, 2)\n",
    "par_ids = create_all_partition_id(partition_each_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sc.parallelize(indexed_data).groupByKey().map(lambda x: [x[0], list(x[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 0, 0), (0, 1, 1), (1, 1, 1)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 0, -1), [48]]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.filter(lambda x: x[0] == (1, 0, -1)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[48][2] == bin_bounds[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.029902170770304"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_bounds[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, -1, 0), [6]]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.filter(lambda x: x[0] == (1, -1, 0)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.11903154, -8.24949825, -7.65189034])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-10.83328933,  -3.16047846,   4.5123324 ]),\n",
       " array([-8.24949825,  1.08437331, 10.41824487]),\n",
       " array([-8.02990217, -0.00886354,  8.01217509])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for bound in bin_bounds:\n",
    "    new_lower_bound = bound[0] - abs(bound[0]) * 0.01\n",
    "    new_upper_bound = bound[-1] + abs(bound[-1]) * 0.01\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
